{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy\n",
    "import dask.array as da\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from numba import guvectorize\n",
    "from sgkit.typing import ArrayLike\n",
    "from dask.diagnostics import ProgressBar, ResourceProfiler\n",
    "\n",
    "def pairwise_distance(\n",
    "    x: ArrayLike,\n",
    "    metric: str = \"euclidean\",\n",
    ") -> np.ndarray:\n",
    "    x = da.asarray(x)\n",
    "    x_distance = da.blockwise(\n",
    "        # Lambda wraps reshape for broadcast\n",
    "        euclidean,\n",
    "        \"jk\",\n",
    "        x,\n",
    "        \"ji\",\n",
    "        x,\n",
    "        \"ki\",\n",
    "        dtype=\"float64\",\n",
    "        concatenate=True,\n",
    "    )\n",
    "    x_distance = da.triu(x_distance, 1) + da.triu(x_distance).T\n",
    "    return x_distance.compute()\n",
    "\n",
    "\n",
    "@guvectorize(  # type: ignore\n",
    "    [\n",
    "        \"void(float32[:, :], float32[:, :], float32[:, :])\",\n",
    "        \"void(float64[:, :], float64[:, :], float64[:, :])\",\n",
    "        \"void(int8[:, :], int8[:, :], float64[:, :])\",\n",
    "    ],\n",
    "    \"(m, k),(n, k)->(m, n)\", target='cuda'\n",
    ")\n",
    "def euclidean(x: ArrayLike, y: ArrayLike, out: ArrayLike) -> None:\n",
    "    o = x.shape[-1]\n",
    "    m = x.shape[0]\n",
    "    n = y.shape[0]\n",
    "\n",
    "    for j in range(m):\n",
    "        for k in range(n):\n",
    "            square_sum = 0.0\n",
    "            for i in range(o):\n",
    "                if x[j, i] >= 0 and y[k, i] >= 0:\n",
    "                    square_sum += (x[j, i] - y[k, i]) ** 2\n",
    "            out[j, k] = math.sqrt(square_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rs = da.random.RandomState(0)\n",
    "rs = da.random.RandomState(RandomState=cupy.random.RandomState)\n",
    "x = rs.normal(10, 1, size=(500, 500), chunks=(100, -1))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with ProgressBar(), ResourceProfiler() as prof:\n",
    "    pairwise_distance(x)\n",
    "prof.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = y = np.arange(9).reshape(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda, float32\n",
    "\n",
    "# Controls threads per block and shared memory usage.\n",
    "# The computation will be done on blocks of TPBxTPB elements.\n",
    "TPB = 16\n",
    "\n",
    "@cuda.jit\n",
    "def fast_matmul(A, B, C):\n",
    "    # Define an array in the shared memory\n",
    "    # The size and type of the arrays must be known at compile time\n",
    "    sA = cuda.shared.array(shape=(TPB, TPB), dtype=float32)\n",
    "    sB = cuda.shared.array(shape=(TPB, TPB), dtype=float32)\n",
    "\n",
    "    x, y = cuda.grid(2)\n",
    "\n",
    "    tx = cuda.threadIdx.x\n",
    "    ty = cuda.threadIdx.y\n",
    "    bpg = cuda.gridDim.x    # blocks per grid\n",
    "\n",
    "    if x >= C.shape[0] and y >= C.shape[1]:\n",
    "        # Quit if (x, y) is outside of valid C boundary\n",
    "        return\n",
    "\n",
    "    # Each thread computes one element in the result matrix.\n",
    "    # The dot product is chunked into dot products of TPB-long vectors.\n",
    "    tmp = 0.\n",
    "    for i in range(bpg):\n",
    "        # Preload data into shared memory\n",
    "        sA[tx, ty] = A[x, ty + i * TPB]\n",
    "        sB[tx, ty] = B[tx + i * TPB, y]\n",
    "\n",
    "        # Wait until all threads finish preloading\n",
    "        cuda.syncthreads()\n",
    "\n",
    "        # Computes partial product on the shared memory\n",
    "        for j in range(TPB):\n",
    "            tmp += sA[tx, j] * sB[j, ty]\n",
    "\n",
    "        # Wait until all threads finish computing\n",
    "        cuda.syncthreads()\n",
    "\n",
    "    C[x, y] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import dask.array as da\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def pairwise_distance(x):\n",
    "    x = da.asarray(x)\n",
    "    x_distance = da.blockwise(\n",
    "        lambda _x, _y: euclidean(_x[:, None, :], _y),\n",
    "        \"jk\",\n",
    "        x,\n",
    "        \"ji\",\n",
    "        x,\n",
    "        \"ki\",\n",
    "        dtype=\"float64\",\n",
    "        concatenate=True,\n",
    "    )\n",
    "    x_distance = da.triu(x_distance, 1) + da.triu(x_distance).T\n",
    "    return x_distance.compute()\n",
    "\n",
    "@guvectorize(  # type: ignore\n",
    "    [\n",
    "        \"void(float32[:], float32[:], float32[:])\",\n",
    "        \"void(float64[:], float64[:], float64[:])\",\n",
    "        \"void(int8[:], int8[:], float64[:])\",\n",
    "    ],\n",
    "    \"(n),(n)->()\", target='cuda'\n",
    ")\n",
    "def euclidean(x, y, out) -> None:\n",
    "    square_sum = 0.0\n",
    "    m = x.shape[0]\n",
    "\n",
    "    for i in range(m):\n",
    "        if x[i] >= 0 and y[i] >= 0:\n",
    "            square_sum += (x[i] - y[i]) ** 2\n",
    "    out[0] = math.sqrt(square_sum)\n",
    "\n",
    "rs = da.random.RandomState(RandomState=cupy.random.RandomState)\n",
    "x = rs.normal(10, 1, size=(500, 500), chunks=(100, -1))\n",
    "pairwise_distance(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda, float32\n",
    "\n",
    "# Controls threads per block and shared memory usage.\n",
    "# The computation will be done on blocks of TPBxTPB elements.\n",
    "TPB = 16\n",
    "\n",
    "@cuda.jit\n",
    "def fast_matmul(A, B, C):\n",
    "    # Define an array in the shared memory\n",
    "    # The size and type of the arrays must be known at compile time\n",
    "    sA = cuda.shared.array(shape=(TPB, TPB), dtype=float32)\n",
    "    sB = cuda.shared.array(shape=(TPB, TPB), dtype=float32)\n",
    "\n",
    "    x, y = cuda.grid(2)\n",
    "\n",
    "    tx = cuda.threadIdx.x\n",
    "    ty = cuda.threadIdx.y\n",
    "    bpg = cuda.gridDim.x    # blocks per grid\n",
    "\n",
    "    if x >= C.shape[0] and y >= C.shape[1]:\n",
    "        # Quit if (x, y) is outside of valid C boundary\n",
    "        return\n",
    "\n",
    "    # Each thread computes one element in the result matrix.\n",
    "    # The dot product is chunked into dot products of TPB-long vectors.\n",
    "    tmp = 0.\n",
    "    for i in range(bpg):\n",
    "        # Preload data into shared memory\n",
    "        sA[tx, ty] = A[x, ty + i * TPB]\n",
    "        sB[tx, ty] = B[tx + i * TPB, y]\n",
    "\n",
    "        # Wait until all threads finish preloading\n",
    "        cuda.syncthreads()\n",
    "\n",
    "        # Computes partial product on the shared memory\n",
    "        for j in range(TPB):\n",
    "            tmp += sA[tx, j] * sB[j, ty]\n",
    "\n",
    "        # Wait until all threads finish computing\n",
    "        cuda.syncthreads()\n",
    "\n",
    "    C[x, y] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "x = np.arange(16).reshape(4, 4)\n",
    "y = np.arange(16).reshape(4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nKernel launch configuration was not specified. Use the syntax:\n\nkernel_function[blockspergrid, threadsperblock](arg0, arg1, ..., argn)\n\nSee https://numba.pydata.org/numba-doc/latest/cuda/kernels.html#kernel-invocation for help.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8b7820c4c55e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfast_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/sgkit/lib/python3.8/site-packages/numba/cuda/compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    851\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0;31m# An attempt to launch an unconfigured kernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_launch_config_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgriddim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblockdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharedmem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: \nKernel launch configuration was not specified. Use the syntax:\n\nkernel_function[blockspergrid, threadsperblock](arg0, arg1, ..., argn)\n\nSee https://numba.pydata.org/numba-doc/latest/cuda/kernels.html#kernel-invocation for help.\n\n"
     ]
    }
   ],
   "source": [
    "fast_matmul(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
